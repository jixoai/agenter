# 集成测试指南

## 测试策略

本项目使用**真实 AI 调用**进行集成测试，不使用 mock。这样可以验证：

1. **工具 AI 的提示词工程**是否有效
2. **结构化输出**是否稳定
3. **流式回忆**的延迟和效果
4. **真实成本**估算

## 运行测试

### 前置条件

```bash
# 1. 确保 .env 配置正确
cp .env.example .env
# 编辑 .env，设置 DEEPSEEK_API_TOKEN

# 2. 安装依赖
bun install
```

### 运行工具 AI 测试

```bash
bun run test:tools
```

测试内容：
- 🧠 海马体（记忆激活）- 2 个测试用例
- 💭 前额叶（工作记忆）- 2 个测试用例
- ❤️ 杏仁核（情感标记）- 4 个测试用例
- ⚖️ 比较器 - 2 个测试用例

**预估成本**: ~$0.02 / 次（使用 deepseek-chat）

### 运行回忆编排器测试

```bash
bun run test:recall
```

测试内容：
- 🎬 完整回忆流程（简单+复杂查询）
- ⚡ 流式性能测试（帧延迟统计）
- ⏹️ 中断响应测试（模拟用户打断）

**预估成本**: ~$0.05 / 次

### 运行全部测试

```bash
bun run test
```

## 测试结果解读

### 工具 AI 测试输出示例

```
🧠 测试海马体 (Hippocampus)
===========================

  测试: 身份查询
  线索: "你知道我叫什么吗"
  ✅ 成功 (850ms)
     激活模式: 从"名字"联想到用户身份相关记忆
     记忆数量: 3
     ● [95%] 用户叫Gaubee...
     ◐ [65%] 上次对话...
```

### 回忆编排器测试输出示例

```
🎬 测试完整回忆流程
====================

📌 测试: 身份查询（简单）
   输入: "你知道我叫什么吗"
   --------------------------------------------------

[001] 🚀 开始回忆
     触发: "你知道我叫什么吗"

[002] 🧠 Activate (Round 1)
     模式: 从"名字"联想到用户身份
     ● [95%] 用户叫Gaubee
     ◐ [45%] 对话上下文

[003] 💭 Working Memory
       [0] 用户叫Gaubee
       [1] _empty

[004] ❤️ 😊 ★ 情感: 85%

[005] ✅ 回忆完成
     目标: 确认用户身份并回答
     计划: 2 步
     关键事实: 3 条
```

## 性能基准

| 指标 | 目标值 | 说明 |
|------|--------|------|
| 首帧延迟 | <500ms | 用户感知到"开始思考" |
| 平均帧延迟 | <800ms | 流畅的动画效果 |
| 总回忆时间 | <3s | 复杂查询不超过3秒 |
| 成功率 | >95% | JSON 结构化输出成功率 |

## 故障排查

### 测试失败常见原因

1. **API Token 无效**
   ```
   ❌ 错误: DEEPSEEK_API_TOKEN 未设置
   ```
   解决: 检查 .env 文件

2. **网络超时**
   ```
   ❌ 失败: fetch failed
   ```
   解决: 检查网络连接，或增加 timeout 配置

3. **结构化输出失败**
   ```
   ❌ 失败: No JSON found in response
   ```
   解决: 检查提示词工程，可能需要调整 temperature

4. **Rate Limit**
   ```
   ❌ 失败: 429 Too Many Requests
   ```
   解决: 增加测试间隔，或升级 API 套餐

## CI/CD 集成

由于测试使用真实 API 调用，**不建议在 CI 中自动运行**（成本和稳定性）。

建议方案：
- 本地开发时手动运行
- 发布前作为 checklist 项目
- 使用 `--smoke-test` 模式（只运行 1 个快速测试）验证连接

```bash
# 快速烟雾测试（只测 1 个用例，成本 <$0.01）
bun run src/test-tool-agents.ts --smoke
```

## 成本估算

基于 DeepSeek API 定价（假设 deepseek-chat）：

| 测试项 | Input Tokens | Output Tokens | 成本 |
|--------|-------------|---------------|------|
| test:tools | ~2K | ~800 | ~$0.015 |
| test:recall | ~4K | ~1.5K | ~$0.04 |
| **总计** | ~6K | ~2.3K | **~$0.055** |

> 💡 建议：每次代码改动后运行一次，每日成本 <$0.50
